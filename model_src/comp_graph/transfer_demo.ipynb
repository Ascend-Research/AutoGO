{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo provides examples of how to load Classification Compute Graph networks and convert them to Human Pose Estimation and Semantic Segmentation networks for use with downstream tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets load an example CG. We'll use two examples, the base 'resnet50.pkl' and AutoGO ResNet 50 Arch 1:\n",
    "import torch as t\n",
    "import pickle\n",
    "import os  # This silences some of the spammy TF messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# NOTE: This gives 'ModuleNotFoundError'\n",
    "with open(\"../../architectures/samples/resnet50/resnet50.pkl\", \"rb\") as f:\n",
    "    resnet50 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That failed because we were not in the top-level of the repository. Loading the CG requires loading its class definition from 'model_src/comp_graph/tf_comp_graph.py', but python doesn't know where 'model_src' is since we're already in the same directory as 'tf_comp_graph.py'.\n",
    "Remedying this problem is why this tutorial is in this folder - not the top-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")  # Append top-level to path\n",
    "\n",
    "with open(\"../../architectures/samples/resnet50/resnet50.pkl\", \"rb\") as f:\n",
    "    resnet50 = pickle.load(f)\n",
    "\n",
    "with open(\"../../architectures/samples/resnet50/autogo_arch1.pkl\", \"rb\") as f:\n",
    "    arch1 = pickle.load(f)\n",
    "\n",
    "# Take a look at number of nodes/edges\n",
    "print(resnet50)\n",
    "print(arch1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these networks have the same number of nodes and edges, but different str_id values (hashes generated from the nodes).\n",
    "If you run them through model_src.comp_graph.tf_comp_graph_utils.compute_cg_flops you will see that arch1 is slightly bigger, per the paper.\n",
    "\n",
    "Anyway, let's make networks pytorch networks from CGs for Classification, Human Pose Estimation and Semantic Segmentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_networks import cg_class, cg_hpe, cg_seg\n",
    "\n",
    "class_input = t.rand(1, 3, 224, 224) # Sample ImageNet input\n",
    "\n",
    "# These functions take filenames as input, not the CG objects. So we'll assign these variables to make things a little easier\n",
    "r50_pkl = \"../../architectures/samples/resnet50/resnet50.pkl\"\n",
    "arch1_pkl = \"../../architectures/samples/resnet50/autogo_arch1.pkl\"\n",
    "\n",
    "r50_class = cg_class(r50_pkl, name=\"ResNet50-Class\", net=True) # Net=False will return the CG.\n",
    "print(f\"ResNet-50 classification network output size: {r50_class(class_input).shape}\")\n",
    "\n",
    "arch1_class = cg_class(arch1_pkl, name=\"Arch1-Class\", net=True)\n",
    "print(f\"AutoGO ResNet50 Arch 1 output size: {arch1_class(class_input).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that works. Now, we need to be a bit more careful when converting arch 1 for HPE/Segmentation, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpe_input = t.rand(1, 3, 256, 256)  # MPII Image size in Zhou et al. 2017 (https://arxiv.org/abs/1704.02447)\n",
    "print(\"Human Pose Estimation\")\n",
    "\n",
    "# NOTE: cg_hpe and cg_seg return the network and some information on the # of output channels\n",
    "r50_hpe, r50_out_c = cg_hpe(r50_pkl, name=\"ResNet50-HPE\", net=True)\n",
    "print(\"ResNet50 HPE number output channels\", r50_out_c)\n",
    "print(f\"ResNet50 HPE network output size: {r50_hpe(hpe_input).shape}\")  # Expect 1, 2048, 8, 8 size\n",
    "\n",
    "# NOTE the value for config_name - required since Arch1 is mutated from ResNet50\n",
    "arch1_hpe, arch1_out_c = cg_hpe(arch1_pkl, config_name=\"resnet50.pkl\", net=True)\n",
    "print(\"AutoGO ResNet50 Arch 1 HPE number output channels\", arch1_out_c)\n",
    "print(f\"AutoGO ResNet50 Arch 1 HPE output size: {arch1_hpe(hpe_input).shape}\")  # Expect 1, 2048, 8, 8 size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_input = t.rand(1, 3, 713, 713)  # Typical for Cityscapes\n",
    "print(\"Human Pose Estimation\")\n",
    "\n",
    "# NOTE: cg_hpe and cg_seg return the network and some information on the # of output channels\n",
    "r50_seg, r50_out_net_params = cg_seg(r50_pkl, name=\"ResNet50-HPE\", net=True)\n",
    "print(\"ResNet50 net params:\", r50_out_net_params)\n",
    "# NOTE: Seg networks return 2 outputs:\n",
    "outputs = r50_seg(seg_input)\n",
    "for i, o in enumerate(outputs):\n",
    "    print(f\"Output {i} shape: {o.shape}\")\n",
    "\n",
    "# NOTE the value for config_name - required since Arch1 is mutated from ResNet50\n",
    "arch1_seg, arch1_out_net_params = cg_seg(arch1_pkl, config_name=\"resnet50.pkl\", net=True)\n",
    "print(\"AutoGO ResNet50 Arch 1 net params:\", arch1_out_net_params)\n",
    "# NOTE: Seg networks return 2 outputs:\n",
    "outputs = arch1_seg(seg_input)\n",
    "for i, o in enumerate(outputs):\n",
    "    print(f\"Output {i} shape: {o.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AM10_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
