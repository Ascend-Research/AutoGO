{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo provides a simple demonstration of how to load a Compute Graph (e.g., .pkl saved by AutoGO, or .pb file) and instantiate it as TensorFlow or PyTorch architecture.\n",
    "We will rely on the CGs in architectures/samples for this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load dependencies\n",
    "import torch as t\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from model_src.comp_graph.tf_comp_graph import OP2I, ComputeGraph\n",
    "from model_src.comp_graph.tf_comp_graph_utils import compute_cg_flops\n",
    "from model_src.comp_graph.tf_comp_graph_output import CompGraphOutputNet as TFOutputNet\n",
    "from model_src.comp_graph.tf_comp_graph_output_torch import CompGraphOutputNet as TorchOutputNet\n",
    "\n",
    "op2i = OP2I().build_from_file()\n",
    "\n",
    "\"\"\"\n",
    "Define some helper functions for loading and inference\n",
    "\"\"\"\n",
    "def load_cg_pb(filename, cg_name=\"MyCG\", res=[32, 32, 3]):\n",
    "    assert filename.endswith(\".pb\")\n",
    "    cg = ComputeGraph(name=cg_name, H=res[0], W=res[1], C_in=res[2])\n",
    "    cg.build_from_pb(filename, op2i, oov_threshold=0.)\n",
    "    return cg\n",
    "\n",
    "def load_cg_pkl(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        cg = pickle.load(f)\n",
    "    return cg \n",
    "\n",
    "def gen_as_tf_inference(cg, op2i, res=[32, 32, 3]):\n",
    "    tf_net = TFOutputNet(op2i, cg)\n",
    "    test_tensor = tf.random.uniform(shape=[1, res[0], res[1], res[2]])\n",
    "    print(f\"Test TensorFlow model with input: {test_tensor.shape}\")\n",
    "    print(f\"Output shape: {tf_net(test_tensor).shape}\")\n",
    "    return tf_net\n",
    "\n",
    "def gen_as_torch_inference(cg, op2i, res=[32, 32, 3]):\n",
    "    torch_net = TorchOutputNet(op2i, cg)\n",
    "    test_tensor = t.rand(1, res[2], res[0], res[1])\n",
    "    print(f\"Test PyTorch model with input: {test_tensor.shape}\")\n",
    "    print(f\"Output shape: {torch_net(test_tensor).shape}\")\n",
    "    return torch_net\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now play around with the CIFAR-10 families.\n",
    "Each family has a folder in `architectures/samples`. This folder contains:\n",
    "- `input_arch.png` -> This is the original architecture we optimized with AutoGO. Its CG pkl file is in `architectures`, and this picture shows how it is segmented by our Byte-Pair Encoding DB.\n",
    "- `best_autogo.pkl` -> CG file for the best architecture found by AutoGO (bold in Table 2)\n",
    "- `best_autogo.png` -> Illustration of the best architecture segmented by our BPE Encoding DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing CIFAR-10 CGs\")\n",
    "families = ['nb101', 'nb201', 'hiaml', 'inception', 'two_path']\n",
    "for family in families:\n",
    "    print(f\"Test {family}\")\n",
    "    cg = load_cg_pkl(f\"architectures/samples/{family}/best_autogo.pkl\")\n",
    "    cg.name = f\"{family}_best\"\n",
    "    print(f\"Architecture FLOPs: {compute_cg_flops(cg, op2i, use_fast_counter=True, div=1e6)}\")\n",
    "    print(\"Inference tests on TensorFlow and PyTorch\")\n",
    "    gen_as_tf_inference(cg, op2i)\n",
    "    gen_as_torch_inference(cg, op2i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now play around with our VGG architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test on VGG\")\n",
    "base_vgg = load_cg_pkl(\"architectures/samples/vgg/vgg16_bn.pkl\")\n",
    "print(f\"Original Architecture FLOPs: {compute_cg_flops(base_vgg, op2i, use_fast_counter=True, div=1e9)}\")\n",
    "print(f\"Original Architecture Nodes/Edges: {len(base_vgg.nodes)}/{len(base_vgg.edge_pairs)}\")\n",
    "autogo_vgg = load_cg_pkl(\"architectures/samples/vgg/vgg_autogo.pkl\")\n",
    "print(f\"AutoGO Architecture FLOPs: {compute_cg_flops(autogo_vgg, op2i, use_fast_counter=True, div=1e9)}\")\n",
    "print(f\"AutoGO Architecture Nodes/Edges: {len(autogo_vgg.nodes)}/{len(autogo_vgg.edge_pairs)}\")\n",
    "print(\"Inference tests on TensorFlow and PyTorch\")\n",
    "gen_as_tf_inference(autogo_vgg, op2i, res=[224, 224, 3])\n",
    "gen_as_torch_inference(autogo_vgg, op2i, res=[224, 224, 3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, EDSR.\n",
    "For this, we have 4 networks:\n",
    "- The original EDSR encoder\n",
    "- EDSR AutoGO Arch 1/2/3\n",
    "\n",
    "For the mutated architecture, `_changes.png` is an image which highlights the subgraph segments present in the mutated model but are **not** in the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test on EDSR\")\n",
    "# Base EDSR architecture is in .pb format, so we load differently\n",
    "base_edsr = load_cg_pb(\"architectures/samples/edsr/edsr_encoder.pb\", cg_name=\"EDSR_Encoder\", res=[320, 180, 64]) # Also uses a different size input, because it is the Encoder in the middle of a larger network.\n",
    "print(f\"Original Architecture FLOPs: {compute_cg_flops(base_edsr, op2i, use_fast_counter=True, div=1e9)}\")\n",
    "print(f\"Original Architecture Nodes/Edges: {len(base_edsr.nodes)}/{len(base_edsr.edge_pairs)}\")\n",
    "\n",
    "edsr_arch1 = load_cg_pkl(\"architectures/samples/edsr/autogo_arch1.pkl\")\n",
    "print(f\"Arch1 Architecture FLOPs: {compute_cg_flops(edsr_arch1, op2i, use_fast_counter=True, div=1e9)}\")\n",
    "print(f\"Arch1 Architecture Nodes/Edges: {len(edsr_arch1.nodes)}/{len(edsr_arch1.edge_pairs)}\")\n",
    "print(\"Inference tests on TensorFlow and PyTorch\")\n",
    "gen_as_tf_inference(edsr_arch1, op2i, res=[320, 180, 64])\n",
    "gen_as_torch_inference(edsr_arch1, op2i, res=[320, 180, 64])\n",
    "\n",
    "edsr_arch2 = load_cg_pkl(\"architectures/samples/edsr/autogo_arch2.pkl\")\n",
    "edsr_arch3 = load_cg_pkl(\"architectures/samples/edsr/autogo_arch3.pkl\")\n",
    "print(f\"Arch2 Architecture FLOPs: {compute_cg_flops(edsr_arch2, op2i, use_fast_counter=True, div=1e9)}\")\n",
    "print(f\"Arch3 Architecture FLOPs: {compute_cg_flops(edsr_arch3, op2i, use_fast_counter=True, div=1e9)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AM10_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
